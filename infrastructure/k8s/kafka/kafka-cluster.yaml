# Kafka Cluster Configuration (Strimzi)
# Feature: 005-oke-dapr-kafka-infra
# Tasks: T072, T073, T074, T075
#
# Single-broker configuration for Always Free tier / development
# For production, increase replicas and add persistent storage

apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: todo-kafka
  namespace: kafka
  labels:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/component: message-broker
    app.kubernetes.io/part-of: todo-app
spec:
  kafka:
    # Kafka version
    version: 3.6.0

    # Single broker for development (increase for production)
    replicas: 1

    # Internal listeners only (no external access)
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true

    # Ephemeral storage (no persistent volume - for Always Free tier)
    # For production, use persistent-claim storage
    storage:
      type: ephemeral

    # Kafka configuration
    config:
      # Replication factors (must be 1 for single broker)
      offsets.topic.replication.factor: 1
      transaction.state.log.replication.factor: 1
      transaction.state.log.min.isr: 1
      default.replication.factor: 1
      min.insync.replicas: 1

      # Log retention
      log.retention.hours: 168  # 7 days
      log.retention.bytes: 1073741824  # 1GB per partition

      # Segment configuration
      log.segment.bytes: 104857600  # 100MB
      log.cleanup.policy: delete

      # Performance tuning
      num.io.threads: 2
      num.network.threads: 2
      num.partitions: 3

      # Consumer group session timeout
      group.initial.rebalance.delay.ms: 3000

    # Resource limits (conservative for Always Free)
    resources:
      requests:
        memory: 1Gi
        cpu: 500m
      limits:
        memory: 2Gi
        cpu: 1

    # JVM options
    jvmOptions:
      -Xms: 512m
      -Xmx: 1024m

    # Metrics configuration (for monitoring)
    metricsConfig:
      type: jmxPrometheusExporter
      valueFrom:
        configMapKeyRef:
          name: kafka-metrics-config
          key: kafka-metrics-config.yaml

  # Zookeeper configuration
  zookeeper:
    # Single replica for development
    replicas: 1

    # Ephemeral storage
    storage:
      type: ephemeral

    # Resource limits
    resources:
      requests:
        memory: 512Mi
        cpu: 250m
      limits:
        memory: 1Gi
        cpu: 500m

    # JVM options
    jvmOptions:
      -Xms: 256m
      -Xmx: 512m

  # Entity operator for managing topics and users
  entityOperator:
    topicOperator:
      resources:
        requests:
          memory: 128Mi
          cpu: 50m
        limits:
          memory: 256Mi
          cpu: 200m
    userOperator:
      resources:
        requests:
          memory: 128Mi
          cpu: 50m
        limits:
          memory: 256Mi
          cpu: 200m

---
# Kafka Metrics Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-metrics-config
  namespace: kafka
  labels:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/component: metrics
data:
  kafka-metrics-config.yaml: |
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    rules:
      # Broker metrics
      - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          topic: "$4"
          partition: "$5"
      - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          broker: "$4:$5"
      - pattern: kafka.server<type=(.+), name=(.+)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
      # Consumer metrics
      - pattern: kafka.consumer<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
        name: kafka_consumer_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          topic: "$4"
          partition: "$5"
      # Producer metrics
      - pattern: kafka.producer<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
        name: kafka_producer_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          topic: "$4"
          partition: "$5"
